{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(100000, 26, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m data_df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(dict_data\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m     49\u001b[0m particles_df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([stuff \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m stuff_index, stuff \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(stuffs) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(counts[stuff_index])])\n\u001b[1;32m---> 50\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data_df, columns \u001b[39m=\u001b[39;49m particles_df)\u001b[39m.\u001b[39massign(datasets \u001b[39m=\u001b[39m [folders\u001b[39m.\u001b[39mindex(folder) \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(event_data))])\n\u001b[0;32m     52\u001b[0m filename \u001b[39m=\u001b[39m path_to_save \u001b[39m+\u001b[39m folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m dataframe\u001b[39m.\u001b[39mto_csv(filename)\n",
      "File \u001b[1;32mc:\\Users\\mhals\\AppData\\Local\\Programs\\Programming\\Interpreters\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             index,\n\u001b[0;32m    697\u001b[0m             columns,\n\u001b[0;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    701\u001b[0m         )\n\u001b[0;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\mhals\\AppData\\Local\\Programs\\Programming\\Interpreters\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:331\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    326\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarray(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[0;32m    334\u001b[0m     shape \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\mhals\\AppData\\Local\\Programs\\Programming\\Interpreters\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:591\u001b[0m, in \u001b[0;36m_prep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    589\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m    590\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 591\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(100000, 26, 8)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = \"C:/Users/mhals/Appdata/Local/Programs/Programming/GitHub/Phys117/Data/Pandas/Individual/\"\n",
    "path_to_save = \"C:/Users/mhals/Appdata/Local/Programs/Programming/GitHub/Phys117/Markus/Pandas_analysis/Subplots/Hub/CSVData/\"\n",
    "folders = [\"Background\", \"BH\", \"Sphaleron\"]\n",
    "stuffs = [\"electron\", \"jet\", \"MET\", \"muon\", \"photon\", \"tau\"]\n",
    "file_amounts = [2, 18, 3]\n",
    "\n",
    "from FilesFunc import files\n",
    "folder_list, filenames_list = files(individual = True, data_path = data_path, folders = folders, stuffs = stuffs, file_amounts = file_amounts)\n",
    "\n",
    "    \n",
    "\n",
    "data_variables = [\"eta\", \"phi\", \"PT\", \"jmass\", \"ntrk\", \"btag\", \"hadem\", \"event#\"]\n",
    "\n",
    "from DataFunc import data\n",
    "\n",
    "def event_counts(event_data):\n",
    "    counts = [0 for stuff in stuffs]\n",
    "    particle_name_index = 0\n",
    "    for event in event_data:\n",
    "        for stuff_index, stuff in enumerate(stuffs):\n",
    "            count = len([0 for particle in event if particle[particle_name_index] == stuff])\n",
    "            counts[stuff_index] = count if counts[stuff_index] < count else counts[stuff_index]\n",
    "    return counts\n",
    "\n",
    "\n",
    "for folder_files, filenames, folder in zip(folder_list, filenames_list, folders):\n",
    "    for file, filename in zip(folder_files, filenames):\n",
    "        event_data = data(file, stuffs, data_variables)\n",
    "        counts = event_counts(event_data)\n",
    "\n",
    "        dict_data = {i: [[np.nan for data_variable in data_variables] for particle in range(np.sum(counts))] for i in range(len(event_data))}\n",
    "        for event_index, event in enumerate(event_data):\n",
    "            event_len = len(event)\n",
    "            for stuff_index, stuff in enumerate(stuffs):\n",
    "                count = counts[stuff_index]\n",
    "                particle_name_index = 0\n",
    "                particles = [particle for particle in event if particle[particle_name_index] == stuff]\n",
    "                for particle_index, particle in enumerate(particles):\n",
    "                    particle_index += int(np.sum(counts[:stuff_index]))\n",
    "                    dict_data[event_index][particle_index] = particle\n",
    "\n",
    "        data_df = np.array(list(dict_data.values())).reshape(len(event_data), np.sum(counts) * len(data_variables))\n",
    "        particles_df = np.array([stuff + str(i) for stuff_index, stuff in enumerate(stuffs) for i in range(counts[stuff_index])])\n",
    "        dataframe = pd.DataFrame(data_df, columns = particles_df).assign(datasets = [folders.index(folder) for event in range(len(event_data))])\n",
    "        \n",
    "        filename = path_to_save + folder + \"/\" + filename + \".csv\"\n",
    "        dataframe.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "192e37e5372867588bf05c86667329964572fb6f73abd1341e9017e451c6727b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
