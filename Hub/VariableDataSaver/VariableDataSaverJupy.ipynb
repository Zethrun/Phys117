{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def work_space(path):\n",
    "    while True:\n",
    "        if os.path.split(path)[1] != \"Programs\":\n",
    "            path = os.path.split(path)[0]\n",
    "        else:\n",
    "            return path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "work_dir = work_space(os.getcwd())\n",
    "data_path = work_dir + \"/Hub/EventData/\"\n",
    "save_path = work_dir + \"/Hub/VariableData/\"\n",
    "\n",
    "folders = os.listdir(data_path)\n",
    "data_files = [data_path + data_file for data_file in folders]\n",
    "stuffs = [\"electron\", \"jet\", \"MET\", \"muon\", \"photon\", \"tau\"]\n",
    "data_variables = [\"HT\", \"met\", \"phi_diff\", \"ptmax\", \"stuff_amount\"]\n",
    "file_amounts = [2, 18, 3]\n",
    "\n",
    "\n",
    "def unpacker(folder_data, new_folder_data):\n",
    "    for nested_list in folder_data:\n",
    "        if type(nested_list) == list:\n",
    "            unpacker(nested_list, new_folder_data)\n",
    "        else:\n",
    "            new_folder_data.append(nested_list)\n",
    "    folder_data = new_folder_data\n",
    "    return folder_data\n",
    "\n",
    "\n",
    "def input_data(event):\n",
    "    name_index = 0\n",
    "    pt_index = name_index + 3\n",
    "    phi_index = name_index + 2\n",
    "\n",
    "    met_particle = [particle for particle in event if particle[name_index] == \"MET\"][0]\n",
    "    met = met_particle[pt_index]\n",
    "\n",
    "    ht = np.sum([particle[pt_index] for particle in event])\n",
    "\n",
    "    stuff_amount = len(event)\n",
    "\n",
    "    ptmax_particle = sorted(event, key = lambda x: x[pt_index])[-1]\n",
    "    ptmax = ptmax_particle[pt_index]\n",
    "    \n",
    "    phi_diff = (ptmax_particle[phi_index] - met_particle[phi_index]) % np.pi\n",
    "    input_list = [ht, met, phi_diff, ptmax, stuff_amount]\n",
    "    \n",
    "    return input_list\n",
    "\n",
    "\n",
    "def dataframe_calc(dataframe):\n",
    "    import ast\n",
    "    dataframe_dict = {}\n",
    "    events = [row for row in dataframe.itertuples(index = False)]\n",
    "    for event_index, event in enumerate(events):\n",
    "        event = [tuple(ast.literal_eval(element)for element in particle.strip(\"()\").split(\", \")) for particle in event if \"nan\" not in particle]\n",
    "        dataframe_dict[event_index] = input_data(event)\n",
    "    input_variables = data_variables\n",
    "    data_df = list(dataframe_dict.values())\n",
    "    dataframe = pd.DataFrame(data_df, columns = input_variables)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def data_binner(data, binsize):\n",
    "    data = unpacker(data, [])\n",
    "\n",
    "    if len(data) == 0:\n",
    "        x = [bin * binsize for bin in range(200)]\n",
    "        y = [0 for bin in range(200)]\n",
    "        return x, y\n",
    "\n",
    "    max_value = np.max(data)\n",
    "    bins = int(np.round(max_value / binsize))\n",
    "    bins = np.arange(0, bins)\n",
    "    data = np.array(data)\n",
    "    x, y = [], []\n",
    "\n",
    "    for bin in range(len(bins)):\n",
    "        temp = data\n",
    "        temp = temp[temp <= (bin + 1/2)*binsize]\n",
    "        temp = temp[(bin - 1/2)*binsize < temp]\n",
    "        if len(temp) != 0:\n",
    "            y.append(len(temp))\n",
    "            x.append(bin*binsize)\n",
    "\n",
    "    y = y/np.sum(y)\n",
    "\n",
    "    return x, y\n",
    " \n",
    "\n",
    "def plot_filter(interval_data, filter_strength):\n",
    "    interval_data = sorted(interval_data)\n",
    "    cutoff = round((len(interval_data) * filter_strength))\n",
    "    interval_data = interval_data[:cutoff]\n",
    "    x_min = np.min(interval_data)\n",
    "    x_max = np.max(interval_data)\n",
    "    extra = (x_max - x_min) / 10\n",
    "    return [x_min - extra, x_max + extra]\n",
    "\n",
    "\n",
    "def plot_data(foldered_dataframes, foldered_filenames):\n",
    "    input_dataframes = foldered_dataframes\n",
    "    output_dataframe = [[dataframe_calc(dataframe) for dataframe in dataframes] for dataframes in input_dataframes]\n",
    "    output_filenames = foldered_filenames\n",
    "\n",
    "    return output_dataframe, output_filenames\n",
    "\n",
    "\n",
    "def sampler(output_dataframe, output_filenames, file_amounts, combine_data):\n",
    "    from random import sample\n",
    "\n",
    "    output_dataframe = [[(dataframe, filename) for dataframe, filename in zip(dataframes, filenames)] for dataframes, filenames in zip(output_dataframe, output_filenames)]\n",
    "    samples = [sample(dataframes, file_amount) for dataframes, file_amount in zip(output_dataframe, file_amounts)]\n",
    "\n",
    "    if combine_data:\n",
    "        output_dataframe = [pd.concat([sample[0] for sample in dataframes]) for dataframes in samples]\n",
    "        labels = folders\n",
    "    else:\n",
    "        output_dataframe = [sample[0] for dataframes in samples for sample in dataframes]\n",
    "        labels = [sample[1] for dataframes in samples for sample in dataframes]\n",
    "    \n",
    "    output_dataframe = unpacker(output_dataframe, [])\n",
    "    lables = unpacker(labels, [])\n",
    "        \n",
    "\n",
    "    return output_dataframe, labels\n",
    "\n",
    "\n",
    "def plotter(data_variables, output_dataframe, output_filenames, filter_strengths, binsizes):\n",
    "\n",
    "    for variable_index, variable in enumerate(data_variables):\n",
    "        fig = plt.figure()\n",
    "        style = \"seaborn-v0_8-darkgrid\"\n",
    "        plt.style.use(style)\n",
    "        title = variable + \" Distribution\"\n",
    "        fig.suptitle(title)\n",
    "        plt.xlabel(variable)\n",
    "        plt.ylabel(\"frequency\")\n",
    "\n",
    "        binsize = binsizes[variable_index] if type(binsizes) == list else binsizes\n",
    "        filter_strength = filter_strengths[variable_index] if type(filter_strengths) == list else filter_strengths\n",
    "        interval = np.concatenate([dataframe[variable] for dataframe in output_dataframe])\n",
    "        plt.xlim(plot_filter(interval, filter_strength))\n",
    "\n",
    "        for dataframe, label in zip(output_dataframe, output_filenames):\n",
    "            raw_data = dataframe[variable]\n",
    "            bins, counts = data_binner(raw_data, binsize)\n",
    "            plt.plot(bins, counts, label = label)\n",
    "        \n",
    "        plt.legend(prop = {'size': 8})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldered_dataframes = []\n",
    "for folder in folders:\n",
    "    dataframes = []\n",
    "    data_files = [data_path + folder + \"/\" + data_file for data_file in os.listdir(data_path + folder)]\n",
    "    for data_file in data_files:\n",
    "        data = pd.read_csv(data_file)\n",
    "        data = data.drop([\"Unnamed: 0\", \"datasets\"], axis = 1)\n",
    "        dataframes.append(data)\n",
    "    foldered_dataframes.append(dataframes)\n",
    "\n",
    "\n",
    "foldered_filenames = []\n",
    "for folder in folders:\n",
    "    filenames = os.listdir(data_path + folder)\n",
    "    foldered_filenames.append(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe, output_filenames = plot_data(foldered_dataframes, foldered_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_dataframes, folder_filenames, folder in zip(output_dataframe, output_filenames, folders):\n",
    "    for dataframe, filename in zip(folder_dataframes, folder_filenames):\n",
    "        file_path = save_path + folder + \"/\" + filename\n",
    "        dataframe.to_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "192e37e5372867588bf05c86667329964572fb6f73abd1341e9017e451c6727b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
